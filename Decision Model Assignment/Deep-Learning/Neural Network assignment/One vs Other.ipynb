{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import resample\n",
    "import itertools\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.utils import np_utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = pd.read_csv(\"pca_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = df_pca.drop(\"Unnamed: 0\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Principal Component 1</th>\n",
       "      <th>Principal Component 2</th>\n",
       "      <th>Principal Component 3</th>\n",
       "      <th>Principal Component 4</th>\n",
       "      <th>Principal Component 5</th>\n",
       "      <th>Principal Component 6</th>\n",
       "      <th>Principal Component 7</th>\n",
       "      <th>Principal Component 8</th>\n",
       "      <th>Principal Component 9</th>\n",
       "      <th>Principal Component 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Principal Component 82</th>\n",
       "      <th>Principal Component 83</th>\n",
       "      <th>Principal Component 84</th>\n",
       "      <th>Principal Component 85</th>\n",
       "      <th>Principal Component 86</th>\n",
       "      <th>Principal Component 87</th>\n",
       "      <th>Principal Component 88</th>\n",
       "      <th>Principal Component 89</th>\n",
       "      <th>Principal Component 90</th>\n",
       "      <th>Release Decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.150333</td>\n",
       "      <td>-0.071206</td>\n",
       "      <td>0.035277</td>\n",
       "      <td>0.078159</td>\n",
       "      <td>0.010680</td>\n",
       "      <td>0.013304</td>\n",
       "      <td>-0.019755</td>\n",
       "      <td>-0.026418</td>\n",
       "      <td>-0.018521</td>\n",
       "      <td>-0.046058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>-0.001290</td>\n",
       "      <td>-0.004443</td>\n",
       "      <td>-0.000603</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>-0.002278</td>\n",
       "      <td>-0.002729</td>\n",
       "      <td>-0.000815</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.127587</td>\n",
       "      <td>-0.042643</td>\n",
       "      <td>-0.039528</td>\n",
       "      <td>0.030215</td>\n",
       "      <td>0.055388</td>\n",
       "      <td>-0.029260</td>\n",
       "      <td>-0.044218</td>\n",
       "      <td>-0.043042</td>\n",
       "      <td>0.024067</td>\n",
       "      <td>-0.017534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005864</td>\n",
       "      <td>0.008839</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.006288</td>\n",
       "      <td>-0.000495</td>\n",
       "      <td>0.002620</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>-0.002889</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.173302</td>\n",
       "      <td>-0.032196</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.036082</td>\n",
       "      <td>0.019383</td>\n",
       "      <td>-0.006957</td>\n",
       "      <td>-0.007135</td>\n",
       "      <td>-0.040764</td>\n",
       "      <td>-0.023660</td>\n",
       "      <td>-0.005569</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001461</td>\n",
       "      <td>-0.003321</td>\n",
       "      <td>-0.001130</td>\n",
       "      <td>-0.002359</td>\n",
       "      <td>0.003970</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>-0.001038</td>\n",
       "      <td>-0.003000</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.104943</td>\n",
       "      <td>-0.114886</td>\n",
       "      <td>0.054070</td>\n",
       "      <td>-0.024135</td>\n",
       "      <td>0.055518</td>\n",
       "      <td>-0.013094</td>\n",
       "      <td>-0.010121</td>\n",
       "      <td>-0.011146</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>-0.002956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.009814</td>\n",
       "      <td>0.006775</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.007096</td>\n",
       "      <td>-0.001337</td>\n",
       "      <td>-0.002772</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.167919</td>\n",
       "      <td>-0.048979</td>\n",
       "      <td>0.009335</td>\n",
       "      <td>0.051351</td>\n",
       "      <td>0.022709</td>\n",
       "      <td>0.004066</td>\n",
       "      <td>-0.054789</td>\n",
       "      <td>-0.016897</td>\n",
       "      <td>0.027231</td>\n",
       "      <td>-0.020771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005635</td>\n",
       "      <td>-0.004517</td>\n",
       "      <td>-0.001881</td>\n",
       "      <td>-0.001931</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.006725</td>\n",
       "      <td>-0.005325</td>\n",
       "      <td>0.003686</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Principal Component 1  Principal Component 2  Principal Component 3  \\\n",
       "0              -0.150333              -0.071206               0.035277   \n",
       "1              -0.127587              -0.042643              -0.039528   \n",
       "2              -0.173302              -0.032196               0.000596   \n",
       "3              -0.104943              -0.114886               0.054070   \n",
       "4              -0.167919              -0.048979               0.009335   \n",
       "\n",
       "   Principal Component 4  Principal Component 5  Principal Component 6  \\\n",
       "0               0.078159               0.010680               0.013304   \n",
       "1               0.030215               0.055388              -0.029260   \n",
       "2               0.036082               0.019383              -0.006957   \n",
       "3              -0.024135               0.055518              -0.013094   \n",
       "4               0.051351               0.022709               0.004066   \n",
       "\n",
       "   Principal Component 7  Principal Component 8  Principal Component 9  \\\n",
       "0              -0.019755              -0.026418              -0.018521   \n",
       "1              -0.044218              -0.043042               0.024067   \n",
       "2              -0.007135              -0.040764              -0.023660   \n",
       "3              -0.010121              -0.011146               0.000877   \n",
       "4              -0.054789              -0.016897               0.027231   \n",
       "\n",
       "   Principal Component 10       ...        Principal Component 82  \\\n",
       "0               -0.046058       ...                      0.001183   \n",
       "1               -0.017534       ...                      0.005864   \n",
       "2               -0.005569       ...                     -0.001461   \n",
       "3               -0.002956       ...                      0.005481   \n",
       "4               -0.020771       ...                      0.005635   \n",
       "\n",
       "   Principal Component 83  Principal Component 84  Principal Component 85  \\\n",
       "0               -0.001290               -0.004443               -0.000603   \n",
       "1                0.008839                0.003453                0.005332   \n",
       "2               -0.003321               -0.001130               -0.002359   \n",
       "3                0.002250                0.009814                0.006775   \n",
       "4               -0.004517               -0.001881               -0.001931   \n",
       "\n",
       "   Principal Component 86  Principal Component 87  Principal Component 88  \\\n",
       "0                0.001508               -0.002278               -0.002729   \n",
       "1                0.006288               -0.000495                0.002620   \n",
       "2                0.003970                0.003404               -0.001038   \n",
       "3                0.000168                0.000743                0.007096   \n",
       "4                0.001328                0.006725               -0.005325   \n",
       "\n",
       "   Principal Component 89  Principal Component 90  Release Decade  \n",
       "0               -0.000815               -0.002403            2000  \n",
       "1                0.000646               -0.002889            2000  \n",
       "2               -0.003000                0.004577            2000  \n",
       "3               -0.001337               -0.002772            2000  \n",
       "4                0.003686                0.000467            2000  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\seaborn\\categorical.py:1428: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  stat_data = remove_na(group_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Samples in the dataset/release decade')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAETCAYAAAAoF0GbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRDRKooiIiEb/H+d1zZjUz/N7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y=\"Release Decade\", data=df_pca)\n",
    "plt.xlabel(\"Audio samples\")\n",
    "plt.ylabel(\"Release Decade\")\n",
    "plt.title(\"Samples in the dataset/release decade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_copy = df_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_change(year):\n",
    "    if year!=2000:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_copy['Release Decade'] = df_pca_copy['Release Decade'].apply(year_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Principal Component 1</th>\n",
       "      <th>Principal Component 2</th>\n",
       "      <th>Principal Component 3</th>\n",
       "      <th>Principal Component 4</th>\n",
       "      <th>Principal Component 5</th>\n",
       "      <th>Principal Component 6</th>\n",
       "      <th>Principal Component 7</th>\n",
       "      <th>Principal Component 8</th>\n",
       "      <th>Principal Component 9</th>\n",
       "      <th>Principal Component 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Principal Component 82</th>\n",
       "      <th>Principal Component 83</th>\n",
       "      <th>Principal Component 84</th>\n",
       "      <th>Principal Component 85</th>\n",
       "      <th>Principal Component 86</th>\n",
       "      <th>Principal Component 87</th>\n",
       "      <th>Principal Component 88</th>\n",
       "      <th>Principal Component 89</th>\n",
       "      <th>Principal Component 90</th>\n",
       "      <th>Release Decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.150333</td>\n",
       "      <td>-0.071206</td>\n",
       "      <td>0.035277</td>\n",
       "      <td>0.078159</td>\n",
       "      <td>0.010680</td>\n",
       "      <td>0.013304</td>\n",
       "      <td>-0.019755</td>\n",
       "      <td>-0.026418</td>\n",
       "      <td>-0.018521</td>\n",
       "      <td>-0.046058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>-0.001290</td>\n",
       "      <td>-0.004443</td>\n",
       "      <td>-0.000603</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>-0.002278</td>\n",
       "      <td>-0.002729</td>\n",
       "      <td>-0.000815</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.127587</td>\n",
       "      <td>-0.042643</td>\n",
       "      <td>-0.039528</td>\n",
       "      <td>0.030215</td>\n",
       "      <td>0.055388</td>\n",
       "      <td>-0.029260</td>\n",
       "      <td>-0.044218</td>\n",
       "      <td>-0.043042</td>\n",
       "      <td>0.024067</td>\n",
       "      <td>-0.017534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005864</td>\n",
       "      <td>0.008839</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.006288</td>\n",
       "      <td>-0.000495</td>\n",
       "      <td>0.002620</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>-0.002889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.173302</td>\n",
       "      <td>-0.032196</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.036082</td>\n",
       "      <td>0.019383</td>\n",
       "      <td>-0.006957</td>\n",
       "      <td>-0.007135</td>\n",
       "      <td>-0.040764</td>\n",
       "      <td>-0.023660</td>\n",
       "      <td>-0.005569</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001461</td>\n",
       "      <td>-0.003321</td>\n",
       "      <td>-0.001130</td>\n",
       "      <td>-0.002359</td>\n",
       "      <td>0.003970</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>-0.001038</td>\n",
       "      <td>-0.003000</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.104943</td>\n",
       "      <td>-0.114886</td>\n",
       "      <td>0.054070</td>\n",
       "      <td>-0.024135</td>\n",
       "      <td>0.055518</td>\n",
       "      <td>-0.013094</td>\n",
       "      <td>-0.010121</td>\n",
       "      <td>-0.011146</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>-0.002956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.009814</td>\n",
       "      <td>0.006775</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.007096</td>\n",
       "      <td>-0.001337</td>\n",
       "      <td>-0.002772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.167919</td>\n",
       "      <td>-0.048979</td>\n",
       "      <td>0.009335</td>\n",
       "      <td>0.051351</td>\n",
       "      <td>0.022709</td>\n",
       "      <td>0.004066</td>\n",
       "      <td>-0.054789</td>\n",
       "      <td>-0.016897</td>\n",
       "      <td>0.027231</td>\n",
       "      <td>-0.020771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005635</td>\n",
       "      <td>-0.004517</td>\n",
       "      <td>-0.001881</td>\n",
       "      <td>-0.001931</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.006725</td>\n",
       "      <td>-0.005325</td>\n",
       "      <td>0.003686</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Principal Component 1  Principal Component 2  Principal Component 3  \\\n",
       "0              -0.150333              -0.071206               0.035277   \n",
       "1              -0.127587              -0.042643              -0.039528   \n",
       "2              -0.173302              -0.032196               0.000596   \n",
       "3              -0.104943              -0.114886               0.054070   \n",
       "4              -0.167919              -0.048979               0.009335   \n",
       "\n",
       "   Principal Component 4  Principal Component 5  Principal Component 6  \\\n",
       "0               0.078159               0.010680               0.013304   \n",
       "1               0.030215               0.055388              -0.029260   \n",
       "2               0.036082               0.019383              -0.006957   \n",
       "3              -0.024135               0.055518              -0.013094   \n",
       "4               0.051351               0.022709               0.004066   \n",
       "\n",
       "   Principal Component 7  Principal Component 8  Principal Component 9  \\\n",
       "0              -0.019755              -0.026418              -0.018521   \n",
       "1              -0.044218              -0.043042               0.024067   \n",
       "2              -0.007135              -0.040764              -0.023660   \n",
       "3              -0.010121              -0.011146               0.000877   \n",
       "4              -0.054789              -0.016897               0.027231   \n",
       "\n",
       "   Principal Component 10       ...        Principal Component 82  \\\n",
       "0               -0.046058       ...                      0.001183   \n",
       "1               -0.017534       ...                      0.005864   \n",
       "2               -0.005569       ...                     -0.001461   \n",
       "3               -0.002956       ...                      0.005481   \n",
       "4               -0.020771       ...                      0.005635   \n",
       "\n",
       "   Principal Component 83  Principal Component 84  Principal Component 85  \\\n",
       "0               -0.001290               -0.004443               -0.000603   \n",
       "1                0.008839                0.003453                0.005332   \n",
       "2               -0.003321               -0.001130               -0.002359   \n",
       "3                0.002250                0.009814                0.006775   \n",
       "4               -0.004517               -0.001881               -0.001931   \n",
       "\n",
       "   Principal Component 86  Principal Component 87  Principal Component 88  \\\n",
       "0                0.001508               -0.002278               -0.002729   \n",
       "1                0.006288               -0.000495                0.002620   \n",
       "2                0.003970                0.003404               -0.001038   \n",
       "3                0.000168                0.000743                0.007096   \n",
       "4                0.001328                0.006725               -0.005325   \n",
       "\n",
       "   Principal Component 89  Principal Component 90  Release Decade  \n",
       "0               -0.000815               -0.002403               1  \n",
       "1                0.000646               -0.002889               1  \n",
       "2               -0.003000                0.004577               1  \n",
       "3               -0.001337               -0.002772               1  \n",
       "4                0.003686                0.000467               1  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_pca.iloc[:,:-1], df_pca.iloc[:,-1], test_size = 0.2, random_state = 0,stratify =  df_pca.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(412276, 90)\n",
      "(103069, 90)\n",
      "(412276,)\n",
      "(103069,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape),print(X_test.shape),print(y_train.shape),print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define early stopping callback\n",
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "modelcheck = ModelCheckpoint('C:\\\\Users\\\\Lenovo\\\\Desktop\\\\ML\\\\Data Mining and Decision Models\\\\Decision Models Assignment\\\\checkpoints\\\\classifier_checkpoint.hdf5',monitor='val_acc',verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()),histogram_freq=1, batch_size=32, write_graph=True, write_grads=True,write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list=[tensorboard,earlystop,modelcheck]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 8,251\n",
      "Trainable params: 8,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 60, activation = 'relu', input_dim = df_pca.shape[1]-1))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 30,  activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 30, activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units =1,  activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 412276 samples, validate on 103069 samples\n",
      "Epoch 1/25\n",
      "412276/412276 [==============================] - 89s 215us/step - loss: 0.5367 - acc: 0.7406 - val_loss: 0.5165 - val_acc: 0.7541\n",
      "Epoch 2/25\n",
      "412276/412276 [==============================] - 81s 197us/step - loss: 0.5222 - acc: 0.7510 - val_loss: 0.5125 - val_acc: 0.7562\n",
      "Epoch 3/25\n",
      "412276/412276 [==============================] - 81s 197us/step - loss: 0.5187 - acc: 0.7530 - val_loss: 0.5099 - val_acc: 0.7575\n",
      "Epoch 4/25\n",
      "412276/412276 [==============================] - 81s 197us/step - loss: 0.5161 - acc: 0.7544 - val_loss: 0.5093 - val_acc: 0.7579\n",
      "Epoch 5/25\n",
      "412276/412276 [==============================] - 81s 197us/step - loss: 0.5142 - acc: 0.7557 - val_loss: 0.5078 - val_acc: 0.7587\n",
      "Epoch 6/25\n",
      "412276/412276 [==============================] - 81s 196us/step - loss: 0.5132 - acc: 0.7570 - val_loss: 0.5081 - val_acc: 0.7594\n",
      "Epoch 7/25\n",
      "412276/412276 [==============================] - 80s 195us/step - loss: 0.5124 - acc: 0.7571 - val_loss: 0.5072 - val_acc: 0.7602\n",
      "Epoch 8/25\n",
      "412276/412276 [==============================] - 80s 195us/step - loss: 0.5111 - acc: 0.7586 - val_loss: 0.5089 - val_acc: 0.7585\n",
      "Epoch 9/25\n",
      "412276/412276 [==============================] - 80s 195us/step - loss: 0.5108 - acc: 0.7577 - val_loss: 0.5057 - val_acc: 0.7596\n",
      "Epoch 10/25\n",
      "412276/412276 [==============================] - 80s 195us/step - loss: 0.5099 - acc: 0.7586 - val_loss: 0.5047 - val_acc: 0.7617\n",
      "Epoch 11/25\n",
      "412276/412276 [==============================] - 82s 199us/step - loss: 0.5092 - acc: 0.7590 - val_loss: 0.5049 - val_acc: 0.7608\n",
      "Epoch 12/25\n",
      "412276/412276 [==============================] - 80s 195us/step - loss: 0.5085 - acc: 0.7596 - val_loss: 0.5050 - val_acc: 0.7613\n",
      "Epoch 13/25\n",
      "412276/412276 [==============================] - 80s 195us/step - loss: 0.5088 - acc: 0.7590 - val_loss: 0.5053 - val_acc: 0.7609\n",
      "Epoch 14/25\n",
      "412276/412276 [==============================] - 80s 195us/step - loss: 0.5083 - acc: 0.7597 - val_loss: 0.5043 - val_acc: 0.7614\n",
      "Epoch 15/25\n",
      "412276/412276 [==============================] - 80s 195us/step - loss: 0.5079 - acc: 0.7597 - val_loss: 0.5045 - val_acc: 0.7604\n",
      "Epoch 00015: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25e437ce908>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train.values, batch_size = 32, epochs = 25,callbacks=callbacks_list,validation_data=(X_test, y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    299003\n",
       "0    216342\n",
       "Name: Release Decade, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca['Release Decade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save_weights(\"classifier_2000.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5801996720643452"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "299003/515345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = pd.read_csv(\"pca_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = df_pca.drop(\"Unnamed: 0\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_change(year):\n",
    "    if year!=1990:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca['Release Decade'] = df_pca['Release Decade'].apply(year_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_pca.iloc[:,:-1], df_pca.iloc[:,-1], test_size = 0.2, random_state = 0,stratify =  df_pca.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 8,251\n",
      "Trainable params: 8,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "classifier_1990 = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier_1990.add(Dense(units = 60, activation = 'relu', input_dim = df_pca.shape[1]-1))\n",
    "classifier_1990.add(Dropout(0.2))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier_1990.add(Dense(units = 30,  activation = 'relu'))\n",
    "classifier_1990.add(Dropout(0.2))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier_1990.add(Dense(units = 30, activation = 'relu'))\n",
    "classifier_1990.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier_1990.add(Dense(units =1,  activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier_1990.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "classifier_1990.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 412276 samples, validate on 103069 samples\n",
      "Epoch 1/25\n",
      "412276/412276 [==============================] - 100s 241us/step - loss: 0.5042 - acc: 0.7619 - val_loss: 0.4903 - val_acc: 0.7703\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'dense_16_sample_weights' with dtype float and shape [?]\n\t [[Node: dense_16_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: dense_14/bias_0_grad/values/_583 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_476_dense_14/bias_0_grad/values\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'dense_16_sample_weights', defined at:\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-46-886a37a0cf3e>\", line 20, in <module>\n    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\models.py\", line 863, in compile\n    **kwargs)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 802, in compile\n    name=name + '_sample_weights'))\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 508, in placeholder\n    x = tf.placeholder(dtype, shape=shape, name=name)\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1808, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 5835, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'dense_16_sample_weights' with dtype float and shape [?]\n\t [[Node: dense_16_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: dense_14/bias_0_grad/values/_583 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_476_dense_14/bias_0_grad/values\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'dense_16_sample_weights' with dtype float and shape [?]\n\t [[Node: dense_16_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: dense_14/bias_0_grad/values/_583 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_476_dense_14/bias_0_grad/values\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-67e6c1e5de43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier_1990\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1002\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1003\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1254\u001b[0m                             \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m                                 \u001b[0mepoch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1256\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1257\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    853\u001b[0m                     \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_val\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m                     \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerged\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m                     \u001b[0msummary_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'dense_16_sample_weights' with dtype float and shape [?]\n\t [[Node: dense_16_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: dense_14/bias_0_grad/values/_583 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_476_dense_14/bias_0_grad/values\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'dense_16_sample_weights', defined at:\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-46-886a37a0cf3e>\", line 20, in <module>\n    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\models.py\", line 863, in compile\n    **kwargs)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 802, in compile\n    name=name + '_sample_weights'))\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 508, in placeholder\n    x = tf.placeholder(dtype, shape=shape, name=name)\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1808, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 5835, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'dense_16_sample_weights' with dtype float and shape [?]\n\t [[Node: dense_16_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: dense_14/bias_0_grad/values/_583 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_476_dense_14/bias_0_grad/values\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "classifier_1990.fit(X_train, y_train.values, batch_size = 32, epochs = 25,callbacks=callbacks_list,validation_data=(X_test, y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_1990.save_weights('classifier_1990.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    390632\n",
       "1    124713\n",
       "Name: Release Decade, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca['Release Decade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24199904918064596"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "124713/df_pca.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.7619"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
